= DevSecOps with OpenShift Platform Plus (60 mins)

== Introduction


This section will showcase how OpenShift Platform Plus (OPP) can be used to provide a comprehensive DevSecOps workflow, with a focus on Software Supply Chain Security throughout the entire process, from development to production.
DevSecOps stands for Development, Security and Operations, and is a hollistic approach that promotes continous security within your DevOps practices. Our example will highlight capabilities such as defining CI/CD pipelines CD with security gates, image scanning and signing, secure storage in a Trusted registry, and deployment to secured clusters with advanced security monitoring and alerting.

Let's examine all the components involved in such a DevSecOps pipeline to deploy our e-commerce application named Globex.

== The advanced DevSecOps pipeline - in-depth look

In this section, we will have a look at the end-to-end DevSecOps pipeline and explore the security gates that are provided in it.

* Login to the openshift console using user *{user}* and password *{password}* using this URL: https://{openshift_console_url}

* In the openshift console left menu, Select the Administrator View, then click on *Pipelines -> Pipelines*, select Project *"{user}-cicd"*, as shown in the screenshot below.

image::/devsecops/pipelines.png[width=80%]

*  Let's have a look at the more advanced devsecops pipeline called "app-globex-ui-pipeline". Click on the pipeline name to get a graphical view.

image::/devsecops/pipeline-view.png[width=100%]

* From the left side menu, select Pipelines -> Pipelines. In the right-side window, select the "PipelineRuns" tab, we can see that the pipeline hasn't been run yet.

Before we do that, let's review the repositories in gitea that will be used by this pipeline to deploy the application using OpenShift GitOps.

== Login to gitea to review the repositories

In a new tab, open Gitea's URL: https://gitea-gitea.{openshift_cluster_ingress_domain}, and then login using SSO:

image::/devsecops/gitea-login-with-sso.png[width=100%]

When you login, make sure to select the `Link Account` tab, do not `Register New Account`. Link the existing account to Keycloak using the provided credentials: username: *{user}*, password: *openshift*.

image::/devsecops/gitea-link-account.png[width=100%]

== Start the Pipeline

We see that the pipeline hasn't been run yet, so let's trigger it using a "PipelineRun".

[.console-input]
[source,sh,subs="attributes",role=execute]
----
cat ~/workshop/content/modules/ROOT/examples/devsecops-pipelinerun.yaml | sed 's/$USERNUM/{usernum}/' | sed 's/$USER/{user}/' | sed 's/$SUBDOMAIN/{subdomain}/' | oc create -f - -n {user}-cicd
----

Here's a look at the content of the pipelineRun used to trigger the pipeline. These are the main parameters that are used by the pipeline tasks to deploy the application:

[source,yaml,subs="+macros,attributes+"]
----
include::ROOT:example$devsecops-pipelinerun.yaml[]
----

* Let's observe the pipeline running. *Open the openshift URL, click on pipelines, then select PipelineRuns*

This will take you to a diagram with the last pipeline execution. Let's now examine the different steps, and focus on the tasks that provide an extra layer of security. In you want more details, you can click on each task to see the logs.

image::/devsecops/pipeline-group1.png[]

In the early stages of the pipeline, we do a traditional source clone, then we verify the code using SonarQube.

You can access your SonarQube instance to check the project using this URL:
https://sonarqube-{user}-cicd.{openshift_cluster_ingress_domain}/projects

* You should be able to see your project

image::/devsecops/sonarqube-project.png[]


* Go back to the pipelineRun view in OpenShift. Now, in the next stages, this is where we have implemented additional security layers that will be detailed below.

image::/devsecops/pipeline-group2.png[]

* *"Build-sign-image"*:

Enhancing Security with Tekton Chains

This task is responsible for building a container image based from our source code, including any changes that were committed. The built container image, along with a new tag and a generated Software Bill of Materials (SBOM) is then pushed to our private quay registry on successful completion. An SBOM is a machine-readable, formally structured complete list of all the components, including modules and libraries, used/required to build a software solution. So, in simple words, a software bill of materials offers an insight into the makeup of an application developed using third-party commercial tools and open-source software.

This task also uses Tekton Chains, a Kubernetes Custom Resource Definition (CRD) controller, that is crucial in augmenting the supply chain security within our OpenShift Pipelines. This toolâ€™s capacity to automatically sign task runs, and its adoption of advanced attestation formats like in-toto, bring a higher degree of trust and verification to our processes.

This task is responsible for emitting two important TaskResults i.e. IMAGE_URL and IMAGE_DIGEST. Those parameters are very important because they are the ones that trigger Tekton Chains to create a digital signature for your container image.

Now let's have a look at the following tasks:

image::/devsecops/pipeline-group3.png[]

* *acs-image-check*: this task uses the roxctl CLI to check build-time violations of your security policies in your image. In this demo, we have set up a policy that verifies signatures on your container image. If this policy is enabled and your container image is unsigned or signed by non trusted source, the pipeline will fail. If the signature is available and is trusted, this pipeline task will complete successfully.

* *acs-image-scan*: The acs-image-scan uses the roxctl CLI to return the components and vulnerabilities found in the image . Any vulnerabilities that exist in packages embedded in the image will be reported.

* *scan-export-sbom*: This task is responsible for scanning any vulnerabilities that exist in our SBOM and exports our SBOM to a externally accessible repository. For scanning, this task uses a 3rd-party tool called Grype which is a vulnerability scanner for container images and filesystems.

That's it! You now have a deeper understanding of the Security capabilities that provide a Trusted Software Supply Chain (or DevSecOps approach), using OpenShift Pipelines (tekton chains), and Red Hat Advanced Cluster Security (Red Hat ACS).


== Using a Trusted image registry to store signed images

Red Hat Quay is a trusted, geo-replicated, security enabled container registry that allows to scan container image for vulnerabitilies, but also store the signed images with all their metadata, such as the generated SBOM files and the signatures. These assets can be used later on in the pipelines for verification and validation purposes, like we have seen in the previous pipeline.

Let's now have a look at container image in Quay, and verify that it has indeed been signed by the pipeline.

* In a new tab, Open the Quay URL: https://registry-quay-quay-operator.{openshift_cluster_ingress_domain}

* Select "Sign in with Keycloak" and login as user *"{user}"* and password *{password}*.

Next, click the *"workshopX/globex-ui"* repository, and click on 'Tags' on the left side menu (replace workshopX with you current user, for example workshop1 for user1).

image::/devsecops/quay-tags.png[]

We can now see all the history of that container image, with all tags, and the associated metadata. We can particularily see that this container image has a small checkmark next to it, hover it to check that it has been correctly signed by Tekton Chains with the DevSecOps pipeline was last run.

You can also click on the *"Show signatures"* button on the top-right side to reveal additional information about the image.

image::/devsecops/quay-image-signed.png[]

Quay also provides a summary of the vulnerabilities of the container image, but since we've already seen that with Red Hat ACS, let's skip to the next section.

That's it, you now have a better understanding of Quay capabilities to store the signed container images, along with the metadata such as SBOMs, signatures etc.


== Defining security policies in Red Hat Advanced Cluster Security (Red Hat ACS)


* In a new tab, open the Red Hat ACS console at https://central-stackrox.{openshift_cluster_ingress_domain}

* Choose the "Keycloak" auth provider as shown below:

image::/devsecops/acs-keycloak.png[]

* Login with Keycloak: username *"clusteradmin"* and password *{password}*.

* Once you are on the Red Hat ACS console, select "Platform Configuration -> Policy Management" from the left-side menu. This should take you to the policies page.

image::/devsecops/acs-policies.png[]

Red Hat ACS provides about 85 out-of-the-box policies to help implement security best practices and sageguards across your fleets of clusters, you can explore some of them by scrolling through the list of policies.

* Let's now look at the "Trusted Image Signature" policy. In the "Filter policies" section, type "Policy" then hit enter, then type "Trusted Signature".

image::/devsecops/acs-trusted-signature-policy.png[]

* Click on the policy to check its details, then select "Actions -> Edit Policy" on the top right side.

image::/devsecops/acs-edit-policy.png[]

On the "Policy Details", you can define the metadata and the Severity level and some other information.

Next, select the "Policy Behavior" and this is where you can define when and how the policy gets applied.

image::/devsecops/acs-policy-details.png[]

The "Lifecycle stages" allow you to define if it's applied at Build, Deploy or Runtime.

The response method provides 2 options:

* *Inform*: the policy only triggers an alert but is not enforced, meaning it takes no specific action.
* *Inform and enforce*: The policy triggers an alert AND is enforced, for example deleting a container that violates a specific policy, or in our previous case by breaking the pipeline because the container image was not signed with a trusted signature.

Finally, the "Configure enforcement behavior" gives you control over how the policy gets enforced, as explained in the different options.

* Next, click on "3-Policy criteria" to explore how the signature verification is implemented. Inside the "Policy Section 1", click on "Select".

image::/devsecops/acs-policy-criteria.png[]

* In the pop-up, click on "cosign", and this will take you to the public signature that is used to verify the container image, in pair with the private signature that is used by OpenShift Pipelines / Tekton Chains to sign the container images after the build. We will talk about the image signing process in more details in the next pipeline.

image::/devsecops/acs-signature-integration.png[]

Let's now see how Red Hat ACS allows you to monitor your cluster security, by inspecting image vulnerabilities.

* On the left-side menu, click on "Vulnerability Management -> Dashboard", then select images on the top-right side

image::/devsecops/acs-vuln-management.png[]

* On the filter section, type "Image" then hit enter, then type "globex-ui:main", and select the one with an "active" image status

image::/devsecops/acs-image-cves.png[]

This will take you to the image details, where you see a listing of all CVEs, all components, and all the deployments that are using this image on the right side panel. This helps you mitigate issues when there's a compromised image for example.

image::/devsecops/acs-image-details.png[]

That's it! You now have a better understanding of how Red Hat ACS allows you to define security policies that can in turn be used within the DevSecOps pipeline as security gates to prevent untrusted / undesirable content from getting into your production environments, and also continuous monitor the security of your multiple clusters and applications across all environments.


== Adopting a GitOps approach for deployments across multiple clusters

As mentioned in the application architecture section, in a typical multicluster scenario, our "Globex" application would be deployed across multiple clusters using a OpenShift GitOps.

Let's explore this step in the pipeline, then have a look at argocd to understand how it uses the manifests to target the desired cluster.

* On the OpenShift console, on the left menu, Select Pipelines -> Pipelines, and select the pipelineRun with the "Succeeded" status (the same one as in the previous section).

image::/devsecops/pipeline-group-4.png[]

* *update-dev-manifest*: This task is responsible for updating the manifests in the git repository, by updating the container image reference in the deployment yaml file, using Kustomize. This is a standard approach when using tools like OpenShift GitOps. Let's have a look at the yaml file in Gitea.

* In a new tab, open Gitea's URL: https://gitea-gitea.{openshift_cluster_ingress_domain}

* Login using the provided credentials: username: *{user}*, password: *openshift*.

* Click on the last commit id, as shown in the screenshot below:

image::/devsecops/gitea-commit-id.png[]

* Take a look at the changes about the container image tag, as seen below. Because OpenShift GitOps is constantly monitoring that GitOps repository, any update to the yaml file triggers a reconciliation with the target DEV environment, namely the {user}-dev namespace, where the application get re-deployed.

image::/devsecops/gitea-updated-manifest.png[]

Let's now switch to OpenShift GitOps to see how the application gets deployed in the DEV namespace.

* Open the OpenShift GitOps URL: https://argocd-server-gitops.{openshift_cluster_ingress_domain}

* Select Login via Keycloak, and login as user *"{user}"* with password *openshift*

* OpenShift GitOps uses a concept of an *"Application"* as a group of manifests stored in a git repository that need to be deployed altogether.
image::/devsecops/argocd-applications.png[]


== Using overlays and Kustomize in the DevSecOps pipeline

A common pattern when deploying an application to multiple environments is to have a a repository that contains the following structure:
 - base: the common assets that we want to deploy
 - overlays
    |_dev: specific values that will override the ones in the base for the "dev" environment
    |_prod: specific values that will override the ones in the base for the "prod" environment


Let's deploy these applications to two namespaces, {user}-dev and {user}-prod

[.console-input]
[source,sh,subs="attributes",role=execute]
----
cd && wget https://raw.githubusercontent.com/AdvancedDevSecOpsWorkshop/workshop/refs/heads/main/content/modules/ROOT/examples/web-nodejs-dev.yaml &&
sed 's/$USER/{user}/' ~/web-nodejs-dev.yaml | oc create -f - -n {user}-argocd
----

and now let's deploy the application in the {user}-prod namespace:

[.console-input]
[source,sh,subs="attributes",role=execute]
----
cd && wget https://raw.githubusercontent.com/AdvancedDevSecOpsWorkshop/workshop/refs/heads/main/content/modules/ROOT/examples/web-nodejs-prod.yaml &&
sed 's/$USER/{user}/' ~/web-nodejs-prod.yaml | oc create -f - -n {user}-argocd
----

We can verify that the applications have been created in OpenShift GitOps by checking the application tiles.

* Go to OpenShift Gitops and select the "app-dev" application in the main page to access the details.

* On the top-left side, click on *"App details"* to access the information about the application, such as the git repository, the branch where the files are located, the target cluster and namespace where the application is deployed, etc.

If we pay closer attention, there are 3 items worth mentioning to understand the multi-environment management:
- REPO_URL: the git repository where our the resources we want to deploy are defined
- TARGET REVISION: the branch to use
- PATH: the folder that contains the specific values for that environment. Here for example, for the "DEV" environment, we use the file located in "globex/overlays/dev".

You can see more details by opening the "gitops" repository in gitea, and navigating to "globex" folder.

image::/devsecops/app-details-dev.png[]

== Deploying to production using a Pull Request in Gitea

We have deployed the same application to the "PROD" environment using the app-prod Application in OpenShift GitOps. The main difference is that the prod version is using "globex/overlays/prod" for the specific values required for production.

Is it common to have a "manual approval" for deploying into a production environment, and in our case, we'll be using a Pull Request to approve the change to the PROD manifests located in "globex/overlays/prod".

The pipeline execution has already created the pull request in the last steps, so let's review it in gitea and merge it to initiate the deployment in the "{user}-prod" namespace through GitOps.

* Open Gitea, select the *gitops* repository and click on *Pull Requests* as seen below:

image::/devsecops/gitea-pull-request.png[]

Click on the pull request and then click on Create Merge Commit, and select create commit:

image::/devsecops/gitea-merge-commit.png[]

* In the Pull Request details, click on *Files Changed*, and you should see that we have updated the image pullspec for the prod environment, as seen below:

image::/devsecops/gitea-merge-changes.png[]


* Close the application details window, and explore the application page to see all the kubernetes resources that are deployed by OpenShift GitOps to the target cluster / namespace, such as the deployments, the services, etc.

* Let's see the same resources deployed in the application namespace *{user}-prod* with this URL: https://{openshift_console_url}/topology/ns/{user}-prod?view=graph

* Let's open the application to verify that it is running as expected:

image::/devsecops/globex-ui.png[]

That's it, you now have a better understanding of how the DevSecOps pipeline is combined with OpenShift GitOps for a multicluster deployment of the "Globex" application.


== Summary

Here a quick summary of all you've seen in this lab:

* OpenShift Platform Plus provided is a comprehensive solution that provides multicluster management (RH ACM, not seen in the lab), continuous security (Red Hat ACS) and a Trusted Registry (Red Hat Quay) that serve as a great foundation to implement a Trusted Software Supply Chain and adopt a DevSecOps approach.

* OpenShift Pipelines (based on Tekton) offers advanced CI/CD capabilities, and allow a direct integration with RH ACS to implement a DevSecOps approach. It also provides advanced capabilities like image signing through the Tekton Chains controller.

* Red Hat Advanced Cluster Security offers out-of-the-box security capabilities such as security policies and image scanning for vulnerabilities to a continuous security monitoring across all your clusters.

* OpenShift GitOps (based on argocd) allows you to adopt a GitOps approach to deploy your application across different environments and multiple clusters, from development to production and all intermediate stages.


== Learning References

https://www.redhat.com/en/blog/red-hat-openshift-and-sigstore[Red Hat OpenShift and Sigstore^]: A comprehensive blog explaining the integration of OpenShift with Cosign.

https://docs.openshift.com/pipelines/1.12/secure/using-tekton-chains-for-openshift-pipelines-supply-chain-security.html[Using Tekton Chains for OpenShift Pipelines Supply Chain Security^]: Detailed documentation on implementing and understanding Tekton Chains within OpenShift.

https://docs.openshift.com/acs/4.2/operating/verify-image-signatures.html[ACS Integration Guide^]: A guide on integrating ACS with Cosign for enhanced container image verification.
